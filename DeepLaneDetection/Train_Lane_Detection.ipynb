{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from Cooking import checkAndCreateDir\n",
    "import helpers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D, Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "train_images = pickle.load(open(\"images/scene/out_reshaped_scenes.p\", \"rb\" ))\n",
    "\n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"images/labelled/out_1d_labels.p\", \"rb\" ))\n",
    "\n",
    "# Make into arrays as the neural network wants these\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize labels\n",
    "labels = labels / 255\n",
    "\n",
    "# Shuffle images along with their labels and split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)\n",
    "\n",
    "# Set optimization parameters\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "model = Sequential()\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# Below layers were re-named for easier reading of model summary; this not necessary\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "# Pooling 1\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Pooling 3\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Upsample 1\n",
    "model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "# Deconv 1\n",
    "model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Upsample 3\n",
    "model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "# Deconv 2\n",
    "model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "\n",
    "# Final layer - only including one channel so 1 filter\n",
    "model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "### End of network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a generator to help the model use less data\n",
    "# Channel shifts help with shadows slightly\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "MODEL_OUTPUT_DIR = 'model/lanes'\n",
    "\n",
    "plateau_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n",
    "checkpoint_filepath = os.path.join(MODEL_OUTPUT_DIR, 'models', '{0}_model.{1}-{2}.h5'.format('model', '{epoch:02d}', '{val_loss:.7f}'))\n",
    "checkAndCreateDir(checkpoint_filepath)\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_filepath, save_best_only=True, verbose=1)\n",
    "csv_callback = CSVLogger(os.path.join(MODEL_OUTPUT_DIR, 'training_log.csv'))\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "callbacks=[plateau_callback, csv_callback, checkpoint_callback, early_stopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 80, 160, 3)        12        \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 78, 158, 8)        224       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 76, 156, 16)       1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 36, 76, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 76, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 38, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 36, 76, 16)        0         \n",
      "_________________________________________________________________\n",
      "Deconv1 (Conv2DTranspose)    (None, 38, 78, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 76, 156, 16)       0         \n",
      "_________________________________________________________________\n",
      "Deconv2 (Conv2DTranspose)    (None, 78, 158, 16)       2320      \n",
      "_________________________________________________________________\n",
      "Final (Conv2DTranspose)      (None, 80, 160, 1)        145       \n",
      "=================================================================\n",
      "Total params: 8,509\n",
      "Trainable params: 0\n",
      "Non-trainable params: 8,509\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=len(X_train)/batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# Save model architecture and weights\n",
    "model.save('model/lanes/trained_lane_model_3_layer_new_2.h5')\n",
    "\n",
    "# Show summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictImage(model, \"images/test/out_scene_965.jpg\")\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predictImage(model, \"images/two-lane-road.jpg\", shape=(452, 602, 3))\n",
    "#res = predictImage(model, \"images/two-lane-road.jpg\", shape=(229, 400, 3))\n",
    "#res = predictImage(model, \"images/two-lane-road.jpg\", shape=(293, 440, 3))\n",
    "    \n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
