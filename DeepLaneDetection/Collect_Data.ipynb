{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AirSimClient import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from skimage.transform import resize\n",
    "from time import sleep\n",
    "import pickle\n",
    "from helpers import nearPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection: \n",
      "Connection established!\n"
     ]
    }
   ],
   "source": [
    "car_client = CarClient()\n",
    "car_client.confirmConnection()\n",
    "car_controls = CarControls()\n",
    "print('Connection established!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: True\n"
     ]
    }
   ],
   "source": [
    "# convert all the segments to one color\n",
    "found = car_client.simSetSegmentationObjectID(\"[\\w]*\", 15, True)\n",
    "# convert one of the lanes to a different color\n",
    "found = car_client.simSetSegmentationObjectID(\"Landscape13\", 19)\n",
    "print(\"Done: %r\" % (found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(car_client, i):\n",
    "        image_response = car_client.simGetImages([ImageRequest(0, AirSimImageType.Segmentation, False, False)])[0]\n",
    "        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    " \n",
    "        #Remove alpha channel\n",
    "        image_rgba = image_rgba[32:132, 0:255, 0:3]\n",
    "        \n",
    "        # remove all the green background color to leave only the label\n",
    "        image_rgba[np.where((image_rgba == [68,218,116]).all(axis = 2))] = [0,0,0]\n",
    "        \n",
    "        image_pil = PIL.Image.fromarray(image_rgba)\n",
    "        \n",
    "        image_pil.save('images/labelled/out_%d.jpg' % i)\n",
    "        np.save('images/labelled/out_%d.npy' % i, image_rgba)\n",
    "\n",
    "        # resize the images to a smaller size so that they're easier to label and convert them to grayscale\n",
    "        \n",
    "        image_pil = PIL.Image.fromarray(image_rgba).convert('L').resize((160, 80), resample=PIL.Image.LANCZOS)\n",
    "        image_data = np.asarray(image_pil.getdata(), dtype=float) / 255.0\n",
    "        \n",
    "        np.save('images/labelled/out_1d_%d.npy' % i, image_data.reshape((80, 160, 1)))\n",
    "        \n",
    "def get_scene(car_client, i, TEST=False):\n",
    "        image_response = car_client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n",
    "        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    " \n",
    "        #Remove alpha channel\n",
    "        image_rgba = image_rgba[32:132, 0:255, 0:3]\n",
    "        \n",
    "        image_pil = PIL.Image.fromarray(image_rgba)\n",
    "        if TEST:\n",
    "            image_pil.save('images/test/out_scene_%d.jpg' % i)\n",
    "        else:\n",
    "        \n",
    "            image_pil.save('images/scene/out_scene_%d.jpg' % i)\n",
    "            np.save('images/scene/out_scene_%d.npy' % i, image_rgba)\n",
    "\n",
    "            # resize the images\n",
    "            image_pil = image_pil.resize((160, 80), resample=PIL.Image.LANCZOS)\n",
    "            image_data = np.asarray(image_pil.getdata(), dtype=float)\n",
    "\n",
    "            np.save('images/scene/out_reshaped_scene_%d.npy' % i, image_data.reshape((80, 160, 3)))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msne-garage01\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\msne-garage01\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "# collect data and save the images both as images and numpy arrays\n",
    "# set location for collecting training data\n",
    "# frame rate is dependent on your particular computer configuration. With an i9 processor and dual-GeForce GTX 1080 TI, 30 FPS is achievable.\n",
    "\n",
    "car_client.simSetPose({b'position': {b'x_val': 858.1627197265625,\n",
    "  b'y_val': -397.84429931640625,\n",
    "  b'z_val': 0.1847546398639679},\n",
    " b'orientation': {b'w_val': 0.9997275471687317,\n",
    "  b'x_val': -0.00038991699693724513,\n",
    "  b'y_val': -0.00528569333255291,\n",
    "  b'z_val': 0.02273230068385601}}, True)\n",
    "\n",
    "\n",
    "endTrainPos = {b'position': {b'x_val': 36.63443374633789,\n",
    "  b'y_val': -17.22163963317871,\n",
    "  b'z_val': 0.1286291480064392},\n",
    " b'orientation': {b'w_val': 0.26637503504753113,\n",
    "  b'x_val': 0.0003908914513885975,\n",
    "  b'y_val': 7.000972982496023e-05,\n",
    "  b'z_val': -0.9638693332672119}}\n",
    "\n",
    "i = 0\n",
    "while(not nearPos(car_client.simGetPose(), endTrainPos)):\n",
    "    get_label(car_client, i)\n",
    "    get_scene(car_client, i)    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msne-garage01\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1210518ec44f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mget_scene\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# collect data every 0.1 seconds and save the images both as images and numpy arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-52c72b399955>\u001b[0m in \u001b[0;36mget_scene\u001b[1;34m(car_client, i, TEST)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mimage_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_rgba\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mimage_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/test/out_scene_%d.jpg'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   1952\u001b[0m             \u001b[1;31m# do what we can to clean up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m                 \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect testing images\n",
    "# set location for collecting test data\n",
    "car_client.simSetPose({b'position': {b'x_val': 858.1627197265625,\n",
    "  b'y_val': -397.84429931640625,\n",
    "  b'z_val': 0.1847546398639679},\n",
    " b'orientation': {b'w_val': 0.9997275471687317,\n",
    "  b'x_val': -0.00038991699693724513,\n",
    "  b'y_val': -0.00528569333255291,\n",
    "  b'z_val': 0.02273230068385601}}, True)\n",
    "\n",
    "endTestPos = {b'position': {b'x_val': 858.1627197265625,\n",
    "  b'y_val': -397.84429931640625,\n",
    "  b'z_val': 0.1847546398639679},\n",
    " b'orientation': {b'w_val': 0.9997275471687317,\n",
    "  b'x_val': -0.00038991699693724513,\n",
    "  b'y_val': -0.00528569333255291,\n",
    "  b'z_val': 0.02273230068385601}}\n",
    "\n",
    "i = 0\n",
    "while(not nearPos(car_client.simGetPose(), endTestPos)):\n",
    "    get_scene(car_client, i, TEST=True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "label_lst = []\n",
    "scene_lst = []\n",
    "\n",
    "RESIZE = True\n",
    "\n",
    "start = 0\n",
    "end = 786\n",
    "\n",
    "for i in range(start, end):\n",
    "    \n",
    "    # If the images aren't properly resized, resize them\n",
    "    if RESIZE:\n",
    "        label = np.load('images/labelled/out_%d.npy' % i)\n",
    "        scene = np.load('images/scene/out_scene_%d.npy' % i)\n",
    "    \n",
    "        image_pil = PIL.Image.fromarray(label).convert('L').resize((160, 80), resample=PIL.Image.LANCZOS)\n",
    "        label = np.asarray(image_pil.getdata(), dtype=float)\n",
    "        label = label.reshape((80,160,1))\n",
    "\n",
    "        image_pil = PIL.Image.fromarray(scene).resize((160, 80), resample=PIL.Image.LANCZOS)\n",
    "        scene = np.asarray(image_pil.getdata(), dtype=float)\n",
    "        scene = scene.reshape((80,160,3))\n",
    "\n",
    "        np.save('images/labelled/out_1d_%d.npy' % i, label)\n",
    "\n",
    "        np.save('images/scene/out_reshaped_scene_%d.npy' % i, scene)\n",
    "    \n",
    "    else:\n",
    "        label = np.load('images/labelled/out_1d_%d.npy' % i)\n",
    "        scene = np.load('images/scene/out_reshaped_scene_%d.npy' % i)\n",
    "        print(label)\n",
    "    \n",
    "    label_lst.append(label)\n",
    "    scene_lst.append(scene)\n",
    "    \n",
    "pickle.dump(label_lst, open('images/labelled/out_1d_labels.p', 'wb'))\n",
    "pickle.dump(scene_lst, open('images/scene/out_reshaped_scenes.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
